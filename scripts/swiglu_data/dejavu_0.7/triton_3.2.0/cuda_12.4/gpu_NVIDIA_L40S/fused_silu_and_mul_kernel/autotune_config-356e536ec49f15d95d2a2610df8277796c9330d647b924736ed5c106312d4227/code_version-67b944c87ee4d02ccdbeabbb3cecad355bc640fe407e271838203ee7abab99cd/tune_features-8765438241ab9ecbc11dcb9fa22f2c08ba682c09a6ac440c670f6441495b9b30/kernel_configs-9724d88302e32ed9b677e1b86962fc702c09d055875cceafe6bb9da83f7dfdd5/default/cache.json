{
    "signature": "JITFunction(triton_swiglu:fused_silu_and_mul_kernel)",
    "total_bench_time_s": 2227.6704761981964,
    "total_configs": 540,
    "current_eval": {},
    "keys": [
        "D",
        "num_tokens",
        "n_elements"
    ],
    "cache": {
        "('16', '16', '512', 'torch.float16', 'torch.float16')": "BLOCK_SIZE: 256, num_warps: 8, num_ctas: 1, num_stages: 4, num_buffers_warp_spec: 0, num_consumer_groups: 0, reg_dec_producer: 0, reg_inc_consumer: 0, maxnreg: None",
        "('32', '16', '1024', 'torch.float16', 'torch.float16')": "BLOCK_SIZE: 256, num_warps: 8, num_ctas: 1, num_stages: 5, num_buffers_warp_spec: 0, num_consumer_groups: 0, reg_dec_producer: 0, reg_inc_consumer: 0, maxnreg: None",
        "('64', '16', '2048', 'torch.float16', 'torch.float16')": "BLOCK_SIZE: 256, num_warps: 8, num_ctas: 1, num_stages: 1, num_buffers_warp_spec: 0, num_consumer_groups: 0, reg_dec_producer: 0, reg_inc_consumer: 0, maxnreg: None"
    },
    "timings": {
        "('16', '16', '512', 'torch.float16', 'torch.float16')": [
            0.0009178563486784697
        ],
        "('32', '16', '1024', 'torch.float16', 'torch.float16')": [
            0.0009205376845784485
        ],
        "('64', '16', '2048', 'torch.float16', 'torch.float16')": [
            0.0009098027949221432
        ]
    },
    "timings_data": {
        "labels": [
            "ms"
        ],
        "rep_t_ms": 100,
        "warmup_t_ms": 25,
        "cuda_graphs": true
    }
}